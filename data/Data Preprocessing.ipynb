{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b92746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import AnonymizedNumber, VALID_SOURCE_GEOGRAPHIC_RESOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a6c7c",
   "metadata": {},
   "source": [
    "### Define Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d06ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR_PATH = Path('.') / 'raw_data'\n",
    "ALIGNMENT_DATA_DIR_PATH =  Path('.') / 'alignment_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b2f6b7",
   "metadata": {},
   "source": [
    "### Load Helper Data\n",
    "\n",
    "This includes a mapping of categorial values to integers (to save space when saving data later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aafe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_state_code_dataframe = pd.read_csv(ALIGNMENT_DATA_DIR_PATH / 'fips_state_codes.csv')\n",
    "\n",
    "numeric_mappings = configparser.ConfigParser()\n",
    "numeric_mappings.optionxform = str\n",
    "numeric_mappings.read('./numeric_mappings.ini')\n",
    "numeric_mappings = {k: int(v) for k, v in dict(numeric_mappings['mapping']).items()}\n",
    "numeric_mappings[np.nan] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdaede",
   "metadata": {},
   "source": [
    "### Load LearnPlatform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcb3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Path('.') / 'processed_data').mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "learnplatform_data_path = (RAW_DATA_DIR_PATH / 'LearnPlatform').resolve()\n",
    "        \n",
    "districts = pd.read_csv(learnplatform_data_path / 'districts_info.csv')\n",
    "products  = pd.read_csv(learnplatform_data_path / 'products_info.csv')\n",
    "\n",
    "engagement = {}\n",
    "for district_engagement_path in (learnplatform_data_path / 'engagement_data').iterdir():\n",
    "    engagement[int(district_engagement_path.stem)] = pd.read_csv(district_engagement_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a109c",
   "metadata": {},
   "source": [
    "### Filter LearnPlatform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1279f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All rows have an anonymized locale if and only if they also have an anonymized\n",
    "## state, which unfortunately means they aren't useful for any kind of prediction,\n",
    "## and can't be augmented with new data. Even worse, they account for 24% of the\n",
    "## total districts . . .\n",
    "unspecified_district_ids = set(districts[pd.isna(districts.state)].district_id)\n",
    "districts = districts[~pd.isna(districts.state)]\n",
    "\n",
    "for unspecified_district_id in unspecified_district_ids:\n",
    "    engagement.pop(int(unspecified_district_id))\n",
    "\n",
    "for district_id, district_dataframe in engagement.items():\n",
    "    engagement[district_id] = district_dataframe[~pd.isna(district_dataframe.engagement_index)]\n",
    "\n",
    "products = {row['LP ID'] : dict(row) for _, row in products.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4dbc4b",
   "metadata": {},
   "source": [
    "### Create Core Dataset (LearnPlatform)\n",
    "\n",
    "Essentially, we resolve the district ID and product ID in each row of the engagement data into actual values (so that all the LearnPlatform data is in the same file).\n",
    "\n",
    "The data for each state -indexed by date and district ID - is saved to its own file.\n",
    "\n",
    "This process only has to be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "908d3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_range(x):\n",
    "    if type(x) == float:\n",
    "        return x\n",
    "    elif type(x) == str:\n",
    "        if '[' in x:\n",
    "            return AnonymizedNumber(x)\n",
    "        else:\n",
    "            return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e422d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALABAMA\n",
      "ALASKA\n",
      "AMERICAN SAMOA\n",
      "ARIZONA\n",
      "Invalid Product ID: nan (District ID 9007, Day 2020-12-08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▍                                                                              | 4/74 [00:02<00:37,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARKANSAS\n",
      "CALIFORNIA\n",
      "Invalid Product ID: nan (District ID 2074, Day 2020-03-13)\n",
      "Invalid Product ID: nan (District ID 9357, Day 2020-12-27)\n",
      "Invalid Product ID: nan (District ID 7164, Day 2020-02-14)\n",
      "Invalid Product ID: nan (District ID 7164, Day 2020-02-18)\n",
      "Invalid Product ID: nan (District ID 7164, Day 2020-02-26)\n",
      "Invalid Product ID: nan (District ID 7164, Day 2020-03-02)\n",
      "Invalid Product ID: nan (District ID 7164, Day 2020-03-10)\n",
      "Invalid Product ID: nan (District ID 7164, Day 2020-03-13)\n",
      "Invalid Product ID: nan (District ID 7164, Day 2020-10-26)\n",
      "Invalid Product ID: nan (District ID 7164, Day 2020-10-27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▊                                                                           | 7/74 [01:27<15:32, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANAL ZONE\n",
      "COLORADO\n",
      "CONNECTICUT\n",
      "Invalid Product ID: nan (District ID 8539, Day 2020-09-29)\n",
      "Invalid Product ID: nan (District ID 8539, Day 2020-09-30)\n",
      "Invalid Product ID: nan (District ID 8539, Day 2020-10-05)\n",
      "Invalid Product ID: nan (District ID 8539, Day 2020-10-16)\n",
      "Invalid Product ID: nan (District ID 8539, Day 2020-10-19)\n",
      "Invalid Product ID: nan (District ID 8539, Day 2020-10-30)\n",
      "Invalid Product ID: nan (District ID 8539, Day 2020-11-05)\n",
      "Invalid Product ID: nan (District ID 8539, Day 2020-11-14)\n",
      "Invalid Product ID: nan (District ID 9589, Day 2020-10-27)\n",
      "Invalid Product ID: nan (District ID 4569, Day 2020-11-04)\n",
      "Invalid Product ID: nan (District ID 4516, Day 2020-09-24)\n",
      "Invalid Product ID: nan (District ID 4516, Day 2020-09-28)\n",
      "Invalid Product ID: nan (District ID 4516, Day 2020-09-29)\n",
      "Invalid Product ID: nan (District ID 4516, Day 2020-11-10)\n",
      "Invalid Product ID: nan (District ID 4516, Day 2020-11-11)\n",
      "Invalid Product ID: nan (District ID 4516, Day 2020-11-15)\n",
      "Invalid Product ID: nan (District ID 4516, Day 2020-11-16)\n",
      "Invalid Product ID: nan (District ID 4516, Day 2020-11-17)\n",
      "Invalid Product ID: nan (District ID 1450, Day 2020-10-07)\n",
      "Invalid Product ID: nan (District ID 1450, Day 2020-10-21)\n",
      "Invalid Product ID: nan (District ID 1450, Day 2020-11-01)\n",
      "Invalid Product ID: nan (District ID 6998, Day 2020-10-10)\n",
      "Invalid Product ID: nan (District ID 8076, Day 2020-08-27)\n",
      "Invalid Product ID: nan (District ID 8127, Day 2020-11-29)\n",
      "Invalid Product ID: nan (District ID 3640, Day 2020-10-24)\n",
      "Invalid Product ID: nan (District ID 3640, Day 2020-11-09)\n",
      "Invalid Product ID: nan (District ID 3640, Day 2020-11-26)\n",
      "Invalid Product ID: nan (District ID 3640, Day 2020-11-27)\n",
      "Invalid Product ID: nan (District ID 3640, Day 2020-11-29)\n",
      "Invalid Product ID: nan (District ID 3640, Day 2020-12-19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████                                                                       | 10/74 [04:26<36:28, 34.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELAWARE\n",
      "DISTRICT OF COLUMBIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▏                                                                     | 11/74 [04:40<31:00, 29.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLORIDA\n",
      "Invalid Product ID: nan (District ID 6919, Day 2020-09-25)\n",
      "Invalid Product ID: nan (District ID 6919, Day 2020-09-28)\n",
      "Invalid Product ID: nan (District ID 6919, Day 2020-11-07)\n",
      "Invalid Product ID: nan (District ID 6919, Day 2020-11-16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                    | 12/74 [05:03<28:40, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEORGIA\n",
      "GUAM\n",
      "HAWAII\n",
      "IDAHO\n",
      "ILLINOIS\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-04-09)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-04-25)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-05-13)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-09-03)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-09-23)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-10-09)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-10-19)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-11-04)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-11-06)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-11-07)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-11-08)\n",
      "Invalid Product ID: nan (District ID 2779, Day 2020-12-01)\n",
      "Invalid Product ID: nan (District ID 8784, Day 2020-03-14)\n",
      "Invalid Product ID: nan (District ID 8784, Day 2020-10-05)\n",
      "Invalid Product ID: nan (District ID 8784, Day 2020-11-13)\n",
      "Invalid Product ID: nan (District ID 8784, Day 2020-12-03)\n",
      "Invalid Product ID: nan (District ID 8784, Day 2020-12-30)\n",
      "Invalid Product ID: nan (District ID 4629, Day 2020-11-24)\n",
      "Invalid Product ID: nan (District ID 4629, Day 2020-12-05)\n",
      "Invalid Product ID: nan (District ID 9553, Day 2020-09-30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▊                                                               | 17/74 [08:29<34:36, 36.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDIANA\n",
      "Invalid Product ID: nan (District ID 3222, Day 2020-10-31)\n",
      "Invalid Product ID: nan (District ID 3222, Day 2020-11-01)\n",
      "Invalid Product ID: nan (District ID 2870, Day 2020-12-24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████                                                             | 19/74 [09:28<29:59, 32.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOWA\n",
      "KANSAS\n",
      "KENTUCKY\n",
      "LOUISIANA\n",
      "MAINE\n",
      "MARYLAND\n",
      "MASSACHUSETTS\n",
      "Invalid Product ID: nan (District ID 5527, Day 2020-09-22)\n",
      "Invalid Product ID: nan (District ID 7305, Day 2020-11-06)\n",
      "Invalid Product ID: nan (District ID 3668, Day 2020-11-29)\n",
      "Invalid Product ID: nan (District ID 3668, Day 2020-12-08)\n",
      "Invalid Product ID: nan (District ID 4949, Day 2020-12-01)\n",
      "Invalid Product ID: nan (District ID 2517, Day 2020-10-14)\n",
      "Invalid Product ID: nan (District ID 9303, Day 2020-02-25)\n",
      "Invalid Product ID: nan (District ID 5882, Day 2020-11-22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▋                                                      | 25/74 [12:00<23:02, 28.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICHIGAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▊                                                     | 26/74 [12:17<21:26, 26.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINNESOTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▉                                                    | 27/74 [12:20<18:06, 23.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSISSIPPI\n",
      "MISSOURI\n",
      "Invalid Product ID: nan (District ID 2956, Day 2020-11-09)\n",
      "Invalid Product ID: nan (District ID 2956, Day 2020-11-10)\n",
      "Invalid Product ID: nan (District ID 2956, Day 2020-11-27)\n",
      "Invalid Product ID: nan (District ID 2956, Day 2020-12-15)\n",
      "Invalid Product ID: nan (District ID 2956, Day 2020-12-31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████▏                                                | 30/74 [13:58<18:40, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONTANA\n",
      "NEBRASKA\n",
      "NEVADA\n",
      "NEW HAMPSHIRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▌                                             | 33/74 [14:07<10:46, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW JERSEY\n",
      "Invalid Product ID: nan (District ID 8256, Day 2020-11-03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▋                                            | 34/74 [14:24<10:35, 15.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW MEXICO\n",
      "NEW YORK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▉                                          | 36/74 [14:45<09:00, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORTH CAROLINA\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-22)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-23)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-24)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-25)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-26)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-27)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-28)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-29)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-09-30)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-01)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-02)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-03)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-04)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-05)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-06)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-07)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-08)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-09)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-10)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-11)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-12)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-13)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-14)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-15)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-16)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-17)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-18)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-19)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-20)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-21)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-22)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-23)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-24)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-25)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-26)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-27)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-28)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-29)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-30)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-10-31)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-01)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-02)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-03)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-04)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-05)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-06)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-07)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-08)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-09)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-10)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-11)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-12)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-13)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-14)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-15)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-16)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-17)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-18)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-19)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-20)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-21)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-22)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-23)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-24)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-25)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-26)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-27)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-29)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-11-30)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-01)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-02)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-03)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-04)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-05)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-06)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-07)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-08)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-09)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-10)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-11)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-12)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-13)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-14)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-15)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-16)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-17)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-18)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-19)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-20)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-21)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-22)\n",
      "Invalid Product ID: nan (District ID 7177, Day 2020-12-28)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-09-23)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-10-09)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-10-15)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-10-18)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-10-23)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-10-25)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-11-12)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-11-15)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-11-30)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-02)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-03)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-10)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-14)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-15)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-16)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-17)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-18)\n",
      "Invalid Product ID: nan (District ID 6584, Day 2020-12-21)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-04-08)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-09-02)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-09-22)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-09-23)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-09-24)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-09-25)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-09-28)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-09-29)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-09-30)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-01)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-02)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-03)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-04)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-05)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-06)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-07)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-08)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-09)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-10)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-11)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-12)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-13)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-14)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-15)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-16)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-17)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-19)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-20)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-21)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-22)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-23)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-24)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-27)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-28)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-29)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-30)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-10-31)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-01)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-02)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-03)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-04)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-05)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-06)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-07)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-09)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-10)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-11)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-12)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-13)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-16)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-17)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-18)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-19)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-20)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-21)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-22)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-23)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-24)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-11-25)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-01)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-02)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-03)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-04)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-07)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-08)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-09)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-10)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-11)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-12)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-14)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-15)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-16)\n",
      "Invalid Product ID: nan (District ID 7767, Day 2020-12-17)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-04-28)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-08-12)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-09-22)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-09-23)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-09-24)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-09-25)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-09-27)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-09-28)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-09-29)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-09-30)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-10-01)\n",
      "Invalid Product ID: nan (District ID 3558, Day 2020-10-02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 37/74 [15:23<11:31, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORTH DAKOTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|██████████████████████████████████████████                                        | 38/74 [15:24<08:54, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHIO\n",
      "Invalid Product ID: nan (District ID 2991, Day 2020-09-30)\n",
      "Invalid Product ID: nan (District ID 2991, Day 2020-12-17)\n",
      "Invalid Product ID: nan (District ID 2060, Day 2020-10-06)\n",
      "Invalid Product ID: nan (District ID 2060, Day 2020-10-21)\n",
      "Invalid Product ID: nan (District ID 2060, Day 2020-11-21)\n",
      "Invalid Product ID: nan (District ID 5150, Day 2020-10-27)\n",
      "Invalid Product ID: nan (District ID 6104, Day 2020-11-29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▎                                     | 40/74 [17:03<14:44, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKLAHOMA\n",
      "OREGON\n",
      "PENNSYLVANIA\n",
      "PUERTO RICO\n",
      "RHODE ISLAND\n",
      "SOUTH CAROLINA\n",
      "SOUTH DAKOTA\n",
      "TENNESSEE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████                              | 47/74 [17:17<03:57,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▏                            | 48/74 [17:34<04:15,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTAH\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-04-28)\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-10-13)\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-11-18)\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-11-20)\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-11-21)\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-11-23)\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-11-27)\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-12-02)\n",
      "Invalid Product ID: nan (District ID 4921, Day 2020-12-30)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-03-27)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-03-28)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-04-03)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-04-13)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-05-13)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-05-29)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-09-24)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-10-09)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-10-20)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-10-21)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-10-22)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-10-23)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-10-24)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-10-29)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-11-15)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-11-20)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-11-23)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-11-29)\n",
      "Invalid Product ID: nan (District ID 9812, Day 2020-12-21)\n",
      "Invalid Product ID: nan (District ID 5231, Day 2020-08-21)\n",
      "Invalid Product ID: nan (District ID 5231, Day 2020-11-12)\n",
      "Invalid Product ID: nan (District ID 7660, Day 2020-02-21)\n",
      "Invalid Product ID: nan (District ID 7660, Day 2020-12-08)\n",
      "Invalid Product ID: nan (District ID 3864, Day 2020-09-24)\n",
      "Invalid Product ID: nan (District ID 3772, Day 2020-10-27)\n",
      "Invalid Product ID: nan (District ID 3772, Day 2020-11-23)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-02-25)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-09-23)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-10-04)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-10-07)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-10-08)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-10-22)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-10-23)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-11-02)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-11-10)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-11-17)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-11-24)\n",
      "Invalid Product ID: nan (District ID 3160, Day 2020-11-30)\n",
      "Invalid Product ID: nan (District ID 9230, Day 2020-11-06)\n",
      "Invalid Product ID: nan (District ID 9230, Day 2020-12-08)\n",
      "Invalid Product ID: nan (District ID 9230, Day 2020-12-10)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-02-24)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-03-09)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-03-13)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-03-17)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-10-16)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-10-28)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-12-04)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-12-08)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-12-10)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-12-11)\n",
      "Invalid Product ID: nan (District ID 4668, Day 2020-12-12)\n",
      "Invalid Product ID: nan (District ID 1270, Day 2020-12-03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████████▎                           | 49/74 [21:07<17:07, 41.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERMONT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▍                          | 50/74 [21:07<13:31, 33.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIRGINIA\n",
      "Invalid Product ID: nan (District ID 1549, Day 2020-09-15)\n",
      "Invalid Product ID: nan (District ID 1791, Day 2020-09-29)\n",
      "Invalid Product ID: nan (District ID 1791, Day 2020-10-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▌                        | 52/74 [21:59<10:39, 29.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIRGIN ISLANDS\n",
      "WASHINGTON\n",
      "Invalid Product ID: nan (District ID 2567, Day 2020-02-18)\n",
      "Invalid Product ID: nan (District ID 2567, Day 2020-02-20)\n",
      "Invalid Product ID: nan (District ID 2567, Day 2020-02-28)\n",
      "Invalid Product ID: nan (District ID 2567, Day 2020-10-01)\n",
      "Invalid Product ID: nan (District ID 2130, Day 2020-12-26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████████████▊                      | 54/74 [23:12<09:47, 29.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEST VIRGINIA\n",
      "WISCONSIN\n",
      "Invalid Product ID: nan (District ID 7752, Day 2020-04-29)\n",
      "Invalid Product ID: nan (District ID 7752, Day 2020-05-28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [23:29<00:00, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WYOMING\n",
      "AMERICAN SAMOA\n",
      "FEDERATED STATES OF MICRONESIA\n",
      "GUAM\n",
      "JOHNSTON ATOLL\n",
      "MARSHALL ISLANDS\n",
      "NORTHERN MARIANA ISLANDS\n",
      "PALAU\n",
      "MIDWAY ISLANDS\n",
      "PUERTO RICO\n",
      "U.S. MINOR OUTLYING ISLANDS\n",
      "NAVASSA ISLAND\n",
      "VIRGIN ISLANDS\n",
      "WAKE ISLAND\n",
      "BAKER ISLAND\n",
      "HOWLAND ISLAND\n",
      "JARVIS ISLAND\n",
      "KINGMAN REEF\n",
      "PALMYRA ATOLL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for state_name_str in tqdm(fips_state_code_dataframe.STATENAME):\n",
    "    print(state_name_str)\n",
    "    \n",
    "    rows = []\n",
    "    indices = []\n",
    "        \n",
    "    for _, district_row in districts[districts.state.str.lower() == state_name_str.lower()].iterrows():\n",
    "        district_row = dict(district_row)\n",
    "        district_id = district_row['district_id']\n",
    "        \n",
    "        for _, row in engagement[district_id].iterrows():\n",
    "            try:\n",
    "                product_row = products[int(row.lp_id)]\n",
    "            except KeyError:\n",
    "                ## It appears the rest of the products were kept in the data despite\n",
    "                ## not being in the top 372 products? I guess I will assign these to\n",
    "                ## an \"other\" category . . .\n",
    "                product_row = {'Sector(s)': 'Other', 'Primary Essential Function': 'Other'}\n",
    "            except ValueError:\n",
    "                print('Invalid Product ID: {} (District ID {}, Day {})'.format(row.lp_id, district_id, row.time))\n",
    "                continue\n",
    "\n",
    "            indices.append((datetime.strptime(row.time, '%Y-%m-%d'), district_id))\n",
    "            rows.append({'engagement;pct_access': row.pct_access,\n",
    "                         'engagement;engagement_index': row.engagement_index,\n",
    "                         'products;Sector(s)': numeric_mappings[product_row['Sector(s)']],\n",
    "                         'products;Primary Essential Function': numeric_mappings[product_row['Primary Essential Function']],\n",
    "                         'districts;state': district_row['state'],\n",
    "                         'districts;locale': district_row['locale'],\n",
    "                         'districts;pct_black/hispanic': parse_range(district_row['pct_black/hispanic']),\n",
    "                         'districts;pct_free/reduced': parse_range(district_row['pct_free/reduced']),\n",
    "                         'districts;county_connections_ratio': parse_range(district_row['county_connections_ratio']),\n",
    "                         'districts;pp_total_raw': parse_range(district_row['pp_total_raw']),\n",
    "                        })\n",
    "\n",
    "    if len(rows) > 0:\n",
    "        index = pd.MultiIndex.from_tuples(indices, names=[\"time\", \"district_id\"])\n",
    "        combined_state_dataframe = pd.DataFrame(rows, index=index)\n",
    "        #combined_state_dataframe.to_csv(Path('.') / 'processed_data' / '{}.csv'.format(state_name_str), index=True)\n",
    "        combined_state_dataframe.to_pickle(Path('.') / 'processed_data' / '{}.gz'.format(state_name_str), \n",
    "                                           compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd848a84",
   "metadata": {},
   "source": [
    "### Add Other Datasets to the Core Dataset\n",
    "\n",
    "Parameters should be defined as follows:\n",
    "    \n",
    "- ```dataframe```: Pandas dataframe that contains all data to be added to the core dataset\n",
    "- ```geographic_resolution_str```: What geographic resolution the new data is at (i.e., 'state', 'zipcode')\n",
    "- ```geographic_id_column_name_str```: What column the identifier for the geographic units of the new data is in\n",
    "- ```output_columns_dict```:  Dictionary mapping column names in ```dataframe``` to column names as they should appear in the updated core dataset\n",
    "- ```crosswalk_by```: What type of weight to use when estimating district-level data from non-district level data. Currently only supports 'area', but I am working on a population weight, too. (See the README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63a9ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dataset(dataframe, \n",
    "                geographic_resolution_str, geographic_id_column_name_str,\n",
    "                output_columns_dict,\n",
    "                crosswalk_by='area'):\n",
    "    \n",
    "    assert geographic_resolution_str in VALID_SOURCE_GEOGRAPHIC_RESOLUTIONS\n",
    "    geo_id_col = {'zipcode': 'ZCTA5CE20', 'state': 'STATEFP'}[geographic_resolution_str]\n",
    "    \n",
    "    weights_dataframe = pd.read_csv(ALIGNMENT_DATA_DIR_PATH / 'weights' / '{}_weights.csv'.format(geographic_resolution_str))\n",
    "    weights_dataframe = weights_dataframe.set_index(geo_id_col)\n",
    "\n",
    "    for state_dataframe_path in tqdm([sdf for sdf in (Path('.') / 'processed_data').iterdir() if sdf.suffix == '.gz']):\n",
    "        state_dataframe = pd.read_pickle(state_dataframe_path)\n",
    "        for v in output_columns_dict.values():\n",
    "            state_dataframe[v] = None\n",
    "\n",
    "        _tmp = fips_state_code_dataframe[fips_state_code_dataframe.STATENAME == state_dataframe_path.stem].iloc[0]\n",
    "        state_id = _tmp.STATEFP\n",
    "        state_name = _tmp.STATENAME.lower()\n",
    "\n",
    "        for locale_type in weights_dataframe.localetype.unique():\n",
    "            ## todo: weight non-numeric (categorical) values?\n",
    "            weighted_output_dict = {v: 0.0 for v in output_columns_dict.values()}\n",
    "            denominator = 0.0\n",
    "\n",
    "            statelocale_weights_dataframe = weights_dataframe[(weights_dataframe.STATEFP == state_id) & \\\n",
    "                                                              (weights_dataframe.localetype == locale_type)]\n",
    "\n",
    "            for geo_id, geo_weights in statelocale_weights_dataframe.iterrows():\n",
    "                row = broadband[broadband[geographic_id_column_name_str] == geo_id]\n",
    "                if len(row) == 1:\n",
    "                    row = row.iloc[0]\n",
    "                elif len(row) > 1:\n",
    "                    raise ValueError\n",
    "                elif len(row) == 0:\n",
    "                    continue\n",
    "\n",
    "                for in_col_name, out_col_name in output_columns_dict.items():\n",
    "                    if not pd.isna(row[in_col_name]):\n",
    "                        if crosswalk_by == 'area':\n",
    "                            weighted_output_dict[out_col_name] += (geo_weights.FRACAREA_TARGET * row[in_col_name])\n",
    "                            denominator += geo_weights.FRACAREA_TARGET\n",
    "                        elif crosswalk_by == 'population':\n",
    "                            raise NotImplementedError\n",
    "                        else:\n",
    "                            raise NotImplementedError\n",
    "\n",
    "            if locale_type == 'Suburban':\n",
    "                locale_type = 'Suburb'\n",
    "                \n",
    "            for v, v_val in weighted_output_dict.items():\n",
    "                state_dataframe.loc[(state_dataframe['districts;state'].str.lower() == state_name) & \\\n",
    "                                    (state_dataframe['districts;locale'] == locale_type), v] = round(v_val / denominator, 5) \\\n",
    "                                                                                               if denominator > 0 else 0.0\n",
    "        #state_dataframe.to_csv(state_dataframe_path, index=False)\n",
    "        state_dataframe.to_pickle(state_dataframe_path, \n",
    "                                  compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c24f2",
   "metadata": {},
   "source": [
    "#### Add BroadbandNow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a5253ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [01:19<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "broadband = pd.read_csv(RAW_DATA_DIR_PATH / 'BroadbandNow' / 'broadband_data_opendatachallenge.csv', encoding='ANSI')\n",
    "\n",
    "def parse(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    elif x.endswith('%'):\n",
    "        return float(x[:-1]) / 100.0\n",
    "    else:\n",
    "        return round(float(x), 2)\n",
    "    \n",
    "broadband['%Access to Terrestrial Broadband'] = broadband['%Access to Terrestrial Broadband'].apply(parse)\n",
    "\n",
    "add_dataset(broadband,\n",
    "            'zipcode', 'Zip',\n",
    "            crosswalk_by='area',\n",
    "            output_columns_dict={'Wired25_3_2020': 'broadband;wired_over_25',\n",
    "                                 'AverageMbps': 'broadband;avg_mbps',\n",
    "                                 '%Access to Terrestrial Broadband': 'broadband;frac_access',\n",
    "                                 'Lowest Priced Terrestrial Broadband Plan': 'broadband;lowest_price',\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c90f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
